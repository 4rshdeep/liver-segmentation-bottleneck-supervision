{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from BSUnet import *\n",
    "import BSUnetModified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 1\n",
    "global_best_metric = 0\n",
    "def read_ct(path):\n",
    "    img = nib.load(path)\n",
    "    img = img.get_data()\n",
    "    return img\n",
    "def loadCT(path):\n",
    "    images = glob.glob(path+\"/volume*\")\n",
    "    segmentations = glob.glob(path+\"/segmentation*\", )\n",
    "    images = sorted(images)\n",
    "    segmentations = sorted(segmentations)\n",
    "    return images , segmentations\n",
    "def preprocess(simg,sseg):\n",
    "    simg[simg>250] = 250\n",
    "    simg[simg<-200] = -200\n",
    "    simg -= -200\n",
    "    simg /= 450\n",
    "    sseg[sseg>0] = 1\n",
    "    return simg , sseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBottleNeckUnet(model,model_checkpoint,autoencoder_model,num_channels=2,num_ct=1,folders=2,batch_size=8,context=2):\n",
    "    \"\"\"\n",
    "        Training by taking ct scans of only num_ct files and each data point of shape\n",
    "        (512,512,num_channels)\n",
    "    \"\"\"\n",
    "    path = \"../data/batch\"\n",
    "    images ,segmentations = loadCT(path)\n",
    "    for i in range(0,len(images),num_ct):\n",
    "        print(\"image \" + str(i)+\" out of \"+str(len(images)))\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        img = read_ct(images[i])\n",
    "        seg = read_ct(segmentations[i])\n",
    "        print(\"Shape of img : \", img.shape)\n",
    "        ##img shape: (512,512,X) X is the sum of all slices of num_ct files\n",
    "        for j in range(0,img.shape[2]):\n",
    "            \n",
    "            z = j - context\n",
    "            data_point, data_point_seg = preprocess(img[:,:,j].astype(float),seg[:,:,j])\n",
    "            data_point = data_point[...,np.newaxis]\n",
    "            while z <= j+context:\n",
    "                if z==j:\n",
    "                    pass\n",
    "                elif z < 0 :\n",
    "                    simg , sseg = preprocess(img[:,:,0].astype(float),seg[:,:,0])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                elif z >= img.shape[2]:\n",
    "                    simg , sseg = preprocess(img[:,:,img.shape[2]-1].astype(float),seg[:,:,img.shape[2]-1])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                else:\n",
    "                    simg , sseg = preprocess(img[:,:,z].astype(float),seg[:,:,z])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                z += 1\n",
    "            ## simg shape (512,512)\n",
    "            ## treating tumor as part of liver\n",
    "            if np.sum(data_point_seg == 1)>0 :\n",
    "                X_train.append(data_point)\n",
    "                y_train.append(data_point_seg)\n",
    "        print(\"Len of X_train \",len(X_train))\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "#         X_train = X_train[...,np.newaxis]\n",
    "        y_train = y_train[...,np.newaxis]\n",
    "        print(\"shape of X_train \",X_train.shape)\n",
    "        print(\"Shape of y_train \",y_train.shape)\n",
    "        \n",
    "#         for k in range(0,X_train.shape[0],batch_size):\n",
    "        output1 = autoencoder_model.predict(y_train)\n",
    "        feature_vectors_autoencoder = output1[1]\n",
    "        model.fit(X_train,[y_train,feature_vectors_autoencoder],callbacks=[model_checkpoint],batch_size=batch_size) ## set epoch to 1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,fromIndex,batch_size=8):\n",
    "    path = \"../data/Test\"\n",
    "    images ,segmentations = loadCT(path)\n",
    "    histot = []\n",
    "    for i in range(fromIndex,len(images)):\n",
    "        print(\"image \" + str(i))\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        img = read_ct(images[i])\n",
    "        seg = read_ct(segmentations[i])\n",
    "        print(\"Shape of img : \", img.shape)\n",
    "        ##img shape: (512,512,X) X is the sum of all slices of num_ct files\n",
    "        for j in range(0,img.shape[2]):\n",
    "            z = j - context\n",
    "            data_point, data_point_seg = preprocess(img[:,:,j].astype(float),seg[:,:,j])\n",
    "            data_point = data_point[...,np.newaxis]\n",
    "            while z <= j+context:\n",
    "                if z==j:\n",
    "                    pass\n",
    "                elif z < 0 :\n",
    "                    simg , sseg = preprocess(img[:,:,0].astype(float),seg[:,:,0])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                elif z >= img.shape[2]:\n",
    "                    simg , sseg = preprocess(img[:,:,img.shape[2]-1].astype(float),seg[:,:,img.shape[2]-1])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                else:\n",
    "                    simg , sseg = preprocess(img[:,:,z].astype(float),seg[:,:,z])\n",
    "                    data_point = np.concatenate([data_point,simg[...,np.newaxis]],axis=2)\n",
    "                z += 1\n",
    "            ## simg shape (512,512)\n",
    "            ## treating tumor as part of liver\n",
    "            if np.sum(data_point_seg == 1)>0 :\n",
    "                X_test.append(data_point)\n",
    "                y_test.append(data_point_seg)\n",
    "        print(\"Len of X_test \",len(X_test))\n",
    "        X_test = np.array(X_test)\n",
    "        y_test = np.array(y_test)\n",
    "#         X_test = X_test[...,np.newaxis]\n",
    "        y_test = y_test[...,np.newaxis]\n",
    "        print(\"shape of X_train \",X_test.shape)\n",
    "        print(\"Shape of y_train \",y_test.shape)\n",
    "        history = model.evaluate(X_test,[y_test,np.zeros((y_test.shape[0],16,16,128))],batch_size=batch_size)\n",
    "        print(history)\n",
    "        histot.append(history)\n",
    "    return histot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 512, 512, 1)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 8)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 512, 512, 8)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 8)  16          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 8)  16          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 8)  584         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 8)  1608        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512, 512, 32) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 512, 8)  2312        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 8)  32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 8)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 512, 512, 16) 1168        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 512, 512, 16) 1168        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 512, 16) 1168        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512, 512, 48) 0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 16) 272         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 16) 2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 48) 0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 32) 13856       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 32) 1056        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 32) 9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 32) 9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 32) 9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 128, 96) 0           conv2d_18[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 64)   55360       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 64)   4160        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 64, 192)  0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 96)   165984      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 96)   9312        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 96)   384         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 96)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 96)   83040       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 96)   83040       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 96)   83040       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 288)  0           conv2d_28[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 128)  331904      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  16512       conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 256)  33024       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 256)  33024       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 256)  33024       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 256)  33024       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 256)  1638656     conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_33[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 256)  2359552     concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 512)  0           activation_7[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 768)  0           concatenate_8[0][0]              \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "feature_vector (Conv2D)         (None, 16, 16, 128)  884864      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         feature_vector[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 128)  0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 96)   49248       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 96)   0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 96)   83040       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 96)   384         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 96)   83040       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 96)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   24640       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, 64, 64)   0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 64, 64, 64)   36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 64)   256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, 64, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 64, 64, 64)   36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 64, 64, 64)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 8224        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128, 128, 32) 0           conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 128, 128, 32) 9248        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 32) 128         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128, 128, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 128, 128, 32) 9248        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 128, 128, 32) 0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 2064        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 256, 256, 16) 0           conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 256, 256, 16) 2320        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 16) 64          conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 256, 256, 16) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 256, 256, 16) 2320        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 256, 256, 16) 0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 512, 512, 16) 1040        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 512, 512, 16) 0           conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 512, 512, 16) 2320        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 512, 512, 16) 64          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 512, 512, 16) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Conv2D)           (None, 512, 512, 1)  145         activation_25[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,887,449\n",
      "Trainable params: 8,884,521\n",
      "Non-trainable params: 2,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_channels = 1\n",
    "autoencoder_baseUnet = BSUnetModified.baseUNet(input_size=(512,512,num_channels),output_ch=(512,512,num_channels))\n",
    "autoencoder_baseUnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_baseUnet.load_weights('./weights/AutoencoderBSUnet/after_epoch1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 512, 512, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 512, 512, 8)  32          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 512, 512, 8)  32          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 512, 512, 8)  32          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 512, 512, 8)  32          max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 512, 512, 8)  584         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 512, 512, 8)  1608        conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 512, 512, 32) 0           conv2d_52[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 512, 512, 8)  2312        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 8)  32          conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 512, 512, 8)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 512, 512, 16) 1168        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 512, 512, 16) 1168        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 512, 512, 16) 1168        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 512, 512, 48) 0           conv2d_59[0][0]                  \n",
      "                                                                 conv2d_60[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 256, 256, 16) 272         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 256, 256, 16) 2320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 256, 256, 16) 2320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 256, 256, 16) 2320        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 256, 256, 48) 0           conv2d_64[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 128, 128, 32) 13856       concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 128, 128, 32) 1056        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 128, 128, 32) 128         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 128, 128, 32) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 128, 128, 32) 9248        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 128, 128, 32) 9248        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 128, 32) 9248        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 128, 128, 96) 0           conv2d_69[0][0]                  \n",
      "                                                                 conv2d_70[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 64, 64, 64)   55360       concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 64)   4160        conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 64, 64, 64)   256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 64, 64, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, 64, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 64, 64, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 64, 64, 64)   36928       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 64, 64, 192)  0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 96)   165984      concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 96)   9312        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 96)   384         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 96)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 96)   83040       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 96)   83040       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 96)   83040       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 32, 32, 288)  0           conv2d_79[0][0]                  \n",
      "                                                                 conv2d_80[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 128)  331904      concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 128)  16512       conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 256)  33024       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 256)  33024       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 256)  33024       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 256)  33024       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 256)  1638656     conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_84[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 256)  2359552     concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 512)  0           activation_32[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 256)  1179904     concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 256)  1024        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 768)  0           concatenate_22[0][0]             \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "feature_vector (Conv2D)         (None, 16, 16, 128)  884864      concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         feature_vector[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 256)  0           batch_normalization_25[0][0]     \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 128)  295040      concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 128)  0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 32, 32, 96)   49248       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 96)   0           conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 32, 32, 96)   83040       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 96)   384         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 96)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 32, 32, 192)  0           activation_38[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 32, 32, 96)   165984      concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 96)   0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 64, 64, 64)   24640       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 64, 64, 64)   0           conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 64, 64, 64)   36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 64, 64, 64)   256         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 64, 64, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 64, 64, 128)  0           activation_41[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 64, 64, 64)   0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 128, 128, 32) 8224        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 128, 128, 32) 0           conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 128, 128, 32) 9248        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 128, 128, 32) 128         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 128, 128, 32) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 128, 128, 64) 0           activation_44[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 128, 128, 32) 0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 256, 256, 16) 2064        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 256, 256, 16) 0           conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 256, 256, 16) 2320        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 256, 256, 16) 64          conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 256, 256, 16) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 256, 256, 32) 0           activation_47[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 256, 256, 16) 4624        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 256, 256, 16) 0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 512, 512, 16) 1040        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 512, 512, 16) 0           conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 512, 512, 16) 2320        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 512, 16) 64          conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 512, 512, 16) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Conv2D)           (None, 512, 512, 1)  17          activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 9,166,169\n",
      "Trainable params: 9,163,241\n",
      "Non-trainable params: 2,928\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_channels = 1\n",
    "num_ct = 1\n",
    "context = 1\n",
    "# model = liverUnet(input_size=(512,512,num_channels))\n",
    "# model = get_unet_sorr(input_size=(512,512,num_channels))\n",
    "model = bottleneckFeatureUnet(input_size=(512,512,1+2*context),output_ch=(512,512,1))\n",
    "model_checkpoint = ModelCheckpoint('./weights/ContextBottleNeckUnet/best_weights.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.summary()\n",
    "# model.load_weights('./weights/BottleNeckBSUnet/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "** epoch  0\n",
      "image 0 out of 111\n",
      "Shape of img :  (512, 512, 685)\n",
      "Len of X_train  276\n",
      "shape of X_train  (276, 512, 512, 3)\n",
      "Shape of y_train  (276, 512, 512, 1)\n",
      "Epoch 1/1\n",
      "276/276 [==============================] - 24s 88ms/step - loss: 48.9961 - final_output_loss: 0.3689 - feature_vector_loss: 97.6233 - final_output_dice_coef: 0.3502 - feature_vector_dice_coef: -44.0789\n",
      "\n",
      "Epoch 00001: loss improved from inf to 48.99610, saving model to ./weights/BottleNeckBSUnet/best_weights.hdf5\n",
      "image 1 out of 111\n",
      "Shape of img :  (512, 512, 683)\n",
      "Len of X_train  259\n",
      "shape of X_train  (259, 512, 512, 3)\n",
      "Shape of y_train  (259, 512, 512, 1)\n",
      "Epoch 1/1\n",
      "259/259 [==============================] - 20s 78ms/step - loss: 26.1975 - final_output_loss: 0.1828 - feature_vector_loss: 52.2122 - final_output_dice_coef: 0.5446 - feature_vector_dice_coef: -67.9850\n",
      "\n",
      "Epoch 00001: loss improved from 48.99610 to 26.19748, saving model to ./weights/BottleNeckBSUnet/best_weights.hdf5\n",
      "image 2 out of 111\n",
      "Shape of img :  (512, 512, 677)\n",
      "Len of X_train  266\n",
      "shape of X_train  (266, 512, 512, 3)\n",
      "Shape of y_train  (266, 512, 512, 1)\n",
      "Epoch 1/1\n",
      "266/266 [==============================] - 18s 67ms/step - loss: 21.6323 - final_output_loss: 0.1355 - feature_vector_loss: 43.1290 - final_output_dice_coef: 0.5289 - feature_vector_dice_coef: -58.0121\n",
      "\n",
      "Epoch 00001: loss improved from 26.19748 to 21.63228, saving model to ./weights/BottleNeckBSUnet/best_weights.hdf5\n",
      "image 3 out of 111\n",
      "Shape of img :  (512, 512, 683)\n",
      "Len of X_train  214\n",
      "shape of X_train  (214, 512, 512, 3)\n",
      "Shape of y_train  (214, 512, 512, 1)\n",
      "Epoch 1/1\n",
      "214/214 [==============================] - 16s 75ms/step - loss: 15.4067 - final_output_loss: 0.1205 - feature_vector_loss: 30.6928 - final_output_dice_coef: 0.4225 - feature_vector_dice_coef: -47.0481\n",
      "\n",
      "Epoch 00001: loss improved from 21.63228 to 15.40666, saving model to ./weights/BottleNeckBSUnet/best_weights.hdf5\n",
      "image 4 out of 111\n",
      "Shape of img :  (512, 512, 781)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-036d4302fa91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"** epoch \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model = trainBottleNeckUnet(model,model_checkpoint,autoencoder_baseUnet,num_channels=num_channels,num_ct=num_ct,folders=1,\n\u001b[0;32m----> 6\u001b[0;31m                                 batch_size=10,context=1)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights/BottleNeckBSUnet/after_epoch{}.hdf5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights/BottleNeckBSUnet/final_weights.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-00213b5e7c5a>\u001b[0m in \u001b[0;36mtrainBottleNeckUnet\u001b[0;34m(model, model_checkpoint, autoencoder_model, num_channels, num_ct, folders, batch_size, context)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0msimg\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msseg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mdata_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m## simg shape (512,512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for e in range(num_epochs):\n",
    "    print(\"*\"*50)\n",
    "    print(\"** epoch \",e)\n",
    "    model = trainBottleNeckUnet(model,model_checkpoint,autoencoder_baseUnet,num_channels=num_channels,num_ct=num_ct,folders=1,\n",
    "                                batch_size=10,context=1)\n",
    "    model.save_weights('./weights/ContextBottleNeckUnet/after_epoch{}.hdf5'.format(e+1))\n",
    "    model.save_weights('./weights/ContextBottleNeckUnet/final_weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/ContextBottleNeckUnet/after_epoch2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 0\n",
      "Shape of img :  (512, 512, 75)\n",
      "Len of X_test  29\n",
      "shape of X_train  (29, 512, 512, 3)\n",
      "Shape of y_train  (29, 512, 512, 1)\n",
      "29/29 [==============================] - 3s 98ms/step\n",
      "[0.9371083830964977, 0.02879622729559397, 1.8454205373237873, 0.8134228818375489, -2.671160065550919e-06]\n",
      "image 1\n",
      "Shape of img :  (512, 512, 123)\n",
      "Len of X_test  29\n",
      "shape of X_train  (29, 512, 512, 3)\n",
      "Shape of y_train  (29, 512, 512, 1)\n",
      "29/29 [==============================] - 1s 29ms/step\n",
      "[0.9766305664490009, 0.03457524123248355, 1.9186858925326118, 0.7770674323566772, -2.7390289437005712e-06]\n",
      "image 2\n",
      "Shape of img :  (512, 512, 501)\n",
      "Len of X_test  181\n",
      "shape of X_train  (181, 512, 512, 3)\n",
      "Shape of y_train  (181, 512, 512, 1)\n",
      "181/181 [==============================] - 5s 30ms/step\n",
      "[0.9503834718498736, 0.020054827469982495, 1.8807121146449726, 0.8604889747439703, -2.377262134465147e-06]\n",
      "image 3\n",
      "Shape of img :  (512, 512, 466)\n",
      "Len of X_test  167\n",
      "shape of X_train  (167, 512, 512, 3)\n",
      "Shape of y_train  (167, 512, 512, 1)\n",
      "167/167 [==============================] - 5s 30ms/step\n",
      "[1.0018660222698827, 0.04163906652993428, 1.9620929785117418, 0.8238208047791804, -2.570824810804961e-06]\n",
      "image 4\n",
      "Shape of img :  (512, 512, 455)\n",
      "Len of X_test  189\n",
      "shape of X_train  (189, 512, 512, 3)\n",
      "Shape of y_train  (189, 512, 512, 1)\n",
      "189/189 [==============================] - 6s 30ms/step\n",
      "[1.0196384159976213, 0.035584063678191453, 2.0036927707611567, 0.8337411534203778, -2.5038674716332928e-06]\n",
      "image 5\n",
      "Shape of img :  (512, 512, 605)\n",
      "Len of X_test  142\n",
      "shape of X_train  (142, 512, 512, 3)\n",
      "Shape of y_train  (142, 512, 512, 1)\n",
      "142/142 [==============================] - 4s 27ms/step\n",
      "[0.8921858987338106, 0.029657304591932138, 1.7547144873041502, 0.6608889247881065, -2.410011831389184e-06]\n",
      "image 6\n",
      "Shape of img :  (512, 512, 588)\n",
      "Len of X_test  139\n",
      "shape of X_train  (139, 512, 512, 3)\n",
      "Shape of y_train  (139, 512, 512, 1)\n",
      "139/139 [==============================] - 4s 30ms/step\n",
      "[0.9839224656708807, 0.022689020778756026, 1.9451559121660191, 0.8671223078820881, -2.550810526856707e-06]\n",
      "image 7\n",
      "Shape of img :  (512, 512, 565)\n",
      "Len of X_test  133\n",
      "shape of X_train  (133, 512, 512, 3)\n",
      "Shape of y_train  (133, 512, 512, 1)\n",
      "133/133 [==============================] - 4s 27ms/step\n",
      "[1.0028900759560722, 0.035296397304680566, 1.9704837485363609, 0.8250072279987031, -2.5258850655518472e-06]\n",
      "image 8\n",
      "Shape of img :  (512, 512, 689)\n",
      "Len of X_test  187\n",
      "shape of X_train  (187, 512, 512, 3)\n",
      "Shape of y_train  (187, 512, 512, 1)\n",
      "187/187 [==============================] - 6s 30ms/step\n",
      "[0.9444692074296309, 0.022938064487531464, 1.866000353971267, 0.8308790692770704, -2.585296440271307e-06]\n",
      "image 9\n",
      "Shape of img :  (512, 512, 826)\n",
      "Len of X_test  198\n",
      "shape of X_train  (198, 512, 512, 3)\n",
      "Shape of y_train  (198, 512, 512, 1)\n",
      "198/198 [==============================] - 6s 30ms/step\n",
      "[0.9466259931073044, 0.01745435584929179, 1.8757976245398473, 0.8639002618023589, -2.4971432415468646e-06]\n",
      "image 10\n",
      "Shape of img :  (512, 512, 845)\n",
      "Len of X_test  189\n",
      "shape of X_train  (189, 512, 512, 3)\n",
      "Shape of y_train  (189, 512, 512, 1)\n",
      "189/189 [==============================] - 5s 27ms/step\n",
      "[0.8838775914812845, 0.00856430208120771, 1.759190876017172, 0.8660348853541084, -2.3836984029104415e-06]\n",
      "image 11\n",
      "Shape of img :  (512, 512, 547)\n",
      "Len of X_test  188\n",
      "shape of X_train  (188, 512, 512, 3)\n",
      "Shape of y_train  (188, 512, 512, 1)\n",
      "188/188 [==============================] - 5s 27ms/step\n",
      "[0.9698018736027657, 0.03517610263673866, 1.9044276361769819, 0.7864517381202994, -2.546916869292506e-06]\n",
      "image 12\n",
      "Shape of img :  (512, 512, 517)\n",
      "Len of X_test  139\n",
      "shape of X_train  (139, 512, 512, 3)\n",
      "Shape of y_train  (139, 512, 512, 1)\n",
      "139/139 [==============================] - 4s 27ms/step\n",
      "[0.9998865972319952, 0.03876020965792855, 1.9610129809208054, 0.8121436956479288, -2.6273513861093084e-06]\n",
      "image 13\n",
      "Shape of img :  (512, 512, 534)\n",
      "Len of X_test  169\n",
      "shape of X_train  (169, 512, 512, 3)\n",
      "Shape of y_train  (169, 512, 512, 1)\n",
      "169/169 [==============================] - 5s 27ms/step\n",
      "[0.9951851293885496, 0.020841977900698694, 1.9695282821824565, 0.8563865597704949, -2.3836608591963767e-06]\n",
      "image 14\n",
      "Shape of img :  (512, 512, 841)\n",
      "Len of X_test  250\n",
      "shape of X_train  (250, 512, 512, 3)\n",
      "Shape of y_train  (250, 512, 512, 1)\n",
      "250/250 [==============================] - 8s 30ms/step\n",
      "[0.901725827217102, 0.11294160353392363, 1.690510058403015, 0.4889167393299285, -2.4855328356352404e-06]\n",
      "image 15\n",
      "Shape of img :  (512, 512, 537)\n",
      "Len of X_test  176\n",
      "shape of X_train  (176, 512, 512, 3)\n",
      "Shape of y_train  (176, 512, 512, 1)\n",
      "176/176 [==============================] - 5s 27ms/step\n",
      "[0.8786354715173895, 0.014167182512623682, 1.7431037588552996, 0.810948741614001, -2.4022931199851882e-06]\n",
      "image 16\n",
      "Shape of img :  (512, 512, 518)\n",
      "Len of X_test  186\n",
      "shape of X_train  (186, 512, 512, 3)\n",
      "Shape of y_train  (186, 512, 512, 1)\n",
      "186/186 [==============================] - 5s 27ms/step\n",
      "[0.9217715961958772, 0.016125049095310432, 1.827418141467597, 0.852274205793673, -2.3359836402334466e-06]\n",
      "image 17\n",
      "Shape of img :  (512, 512, 541)\n",
      "Len of X_test  177\n",
      "shape of X_train  (177, 512, 512, 3)\n",
      "Shape of y_train  (177, 512, 512, 1)\n",
      "177/177 [==============================] - 5s 27ms/step\n",
      "[0.9487252642879378, 0.02392551877225439, 1.8735250039289226, 0.8613388352635406, -2.421737267751027e-06]\n",
      "image 18\n",
      "Shape of img :  (512, 512, 541)\n",
      "Len of X_test  179\n",
      "shape of X_train  (179, 512, 512, 3)\n",
      "Shape of y_train  (179, 512, 512, 1)\n",
      "179/179 [==============================] - 5s 27ms/step\n",
      "[0.9252287612281032, 0.018404137373085046, 1.832053390295146, 0.858311032394452, -2.3945849839215525e-06]\n",
      "image 19\n",
      "Shape of img :  (512, 512, 549)\n",
      "Len of X_test  173\n",
      "shape of X_train  (173, 512, 512, 3)\n",
      "Shape of y_train  (173, 512, 512, 1)\n",
      "173/173 [==============================] - 5s 30ms/step\n",
      "[0.9307358843742768, 0.017709133749547808, 1.8437626272267689, 0.8564483927410753, -2.320300985315769e-06]\n"
     ]
    }
   ],
   "source": [
    "h = evaluate(model,0,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alps = np.array(h)\n",
    "mean = np.mean(alps,axis=0)\n",
    "print(mean[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
